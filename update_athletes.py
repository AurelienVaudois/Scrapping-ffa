###############################################
# update_athletes.py â€“ mise Ã  jour incrÃ©mentale
###############################################
"""RafraÃ®chit la base athlÃ¨tes / rÃ©sultats.

â€¢Â Mode oneâ€‘shot (par dÃ©faut)        : traite â‰¤Â BATCH_SIZE athlÃ¨tes
â€¢Â Mode boucle  --loop               : rÃ©pÃ¨te des miniâ€‘batches jusquâ€™Ã 
  ce que tous les athlÃ¨tes soient Ã  jour, avec une pause --delay.

DÃ©pend dâ€™un helper Â«Â lecture seuleÂ Â» dans *wa_utils.py* :

    def fetch_wa_results_df(name: str) -> pd.DataFrame

qui retourne un DataFrame dÃ©jÃ  nettoyÃ© sans rien Ã©crire en DB.
"""
from __future__ import annotations

import os
import time
import logging
import argparse
from typing import Dict, List

import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from dotenv import load_dotenv

# â”€â”€â”€ utils projet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from src.utils.ffa_fast import get_all_results_fast
from src.utils.athlete_utils import (
    clean_and_prepare_results_df,
    save_athlete_info,
    save_results_to_postgres,
)
from src.utils.wa_utils import fetch_wa_results_df   # â† nouveau helper

# â”€â”€â”€ configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
DB_URL        = os.getenv("DB_URL")
DEFAULT_BATCH = int(os.getenv("BATCH_SIZE", 10))
MAX_AGE_DAYS  = int(os.getenv("MAX_AGE_DAYS", 7))
DEFAULT_DELAY = int(os.getenv("DELAY_SECONDS", 600))  # 10Â min

if not DB_URL:
    raise SystemExit("âŒ  DB_URL manquant dans lâ€™environnement")

engine: Engine = create_engine(
    DB_URL,
    pool_pre_ping=True,
    pool_recycle=300,
    pool_size=5,
    max_overflow=10,
)
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")

# â”€â”€â”€ sÃ©lection des athlÃ¨tes Ã  rafraÃ®chir â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def select_stale_athletes(engine: Engine, batch_size: int) -> List[Dict]:
    q = text(
        """
        SELECT seq, name, club, sex, last_update
          FROM athletes
         WHERE last_update IS NULL
            OR last_update < (NOW() AT TIME ZONE 'utc') - INTERVAL :age
         ORDER BY last_update NULLS FIRST
         LIMIT :limit
        """
    )
    with engine.begin() as conn:
        rows = (
            conn.execute(q, {"age": f"{MAX_AGE_DAYS} days", "limit": batch_size})
            .mappings()
            .all()
        )
    return [dict(r) for r in rows]

# â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _touch(seq: str, name: str, club: str, sex: str, engine: Engine):
    """Met Ã  jour la colonne *last_update*."""
    save_athlete_info(seq, name, club, sex, engine)


def refresh_ffa(ath: Dict, engine: Engine):
    seq, name, club, sex = ath["seq"], ath["name"], ath["club"], ath["sex"]
    df = get_all_results_fast(seq)
    if df.empty:
        logging.info("   â†³ aucune donnÃ©e FFA trouvÃ©e pour %s", seq)
        _touch(seq, name, club, sex, engine)
        return

    df = clean_and_prepare_results_df(df, seq)
    with engine.begin() as conn:
        last_date = conn.scalar(text("SELECT MAX(date) FROM results WHERE seq = :s"), {"s": seq})
    if last_date is not None:
        df = df[df["date"] > pd.Timestamp(last_date)]

    if df.empty:
        logging.info("   â†³ rien de nouveau pour %s", seq)
        _touch(seq, name, club, sex, engine)
        return

    ins = save_results_to_postgres(df, seq, engine)
    logging.info("   â†³ %d nouvelles lignes insÃ©rÃ©es", ins)
    _touch(seq, name, club, sex, engine)


def refresh_wa(ath: Dict, engine: Engine):
    """Scrape WA puis insÃ¨re seulement les nouvelles performances."""
    seq, name, club, sex = ath["seq"], ath["name"], ath["club"], ath["sex"]

    df = fetch_wa_results_df(name)  # DataFrame dÃ©jÃ  nettoyÃ©, pas dâ€™insert
    if df.empty:
        logging.info("   â†³ aucune donnÃ©e WA pour %s", name)
        _touch(seq, name, club, sex, engine)
        return

    # filtre incrÃ©mental
    with engine.begin() as conn:
        last = conn.scalar(text("SELECT MAX(date) FROM results WHERE seq = :s"), {"s": seq})
    if last is not None:
        df = df[df["date"] > pd.Timestamp(last)]

    if df.empty:
        logging.info("   â†³ rien de nouveau pour %s", name)
    else:
        inserted = save_results_to_postgres(df, seq, engine)
        logging.info("   â†³ %d nouvelles lignes insÃ©rÃ©es", inserted)

    _touch(seq, name, club, sex, engine)


def process_batch(batch_size: int) -> int:
    """Traite un batch et renvoie le nombre dâ€™athlÃ¨tes rafraÃ®chis."""
    stale = select_stale_athletes(engine, batch_size)
    if not stale:
        logging.info("âœ… Base dÃ©jÃ  Ã  jour â€“ aucune action nÃ©cessaire.")
        return 0

    logging.info("â¡ï¸  %d athlÃ¨te(s) Ã  mettre Ã  jour (batch=%d, seuil=%dj)", len(stale), batch_size, MAX_AGE_DAYS)
    for ath in stale:
        logging.info("â€¢ RafraÃ®chissement %s (%s)", ath["name"], ath["seq"])
        try:
            if str(ath["seq"]).startswith("WA_"):
                refresh_wa(ath, engine)
            else:
                refresh_ffa(ath, engine)
        except Exception:
            logging.exception("   â†³ Erreur sur %s", ath["seq"])
    logging.info("ğŸ Batch terminÃ©.")
    return len(stale)

# â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="Mise Ã  jour incrÃ©mentale athletes/results")
    parser.add_argument("--loop", action="store_true", help="boucle jusquâ€™Ã  mise Ã  jour complÃ¨te")
    parser.add_argument("--delay", type=int, default=DEFAULT_DELAY, help="dÃ©lai entre batches en secondes")
    parser.add_argument("--batch", type=int, default=DEFAULT_BATCH, help="taille du batch (par ex. 10)")
    args = parser.parse_args()

    if args.loop:
        while True:
            count = process_batch(args.batch)
            if count == 0:
                break
            logging.info("â³ Pause %dâ€¯s avant batch suivantâ€¦", args.delay)
            time.sleep(args.delay)
    else:
        process_batch(args.batch)


if __name__ == "__main__":
    main()
