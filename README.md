# ğŸƒâ€â™‚ï¸ AthlÃ© Analyse (Scrapping-ffa)

Application d'analyse et de suivi des performances d'athlÃ©tisme, agrÃ©geant les donnÃ©es de la **FÃ©dÃ©ration FranÃ§aise d'AthlÃ©tisme (FFA)** et de **World Athletics (WA)**.

Ce projet permet de visualiser l'Ã©volution des performances sur diffÃ©rentes distances (Sprint, Demi-fond, Fond, Route), puis de comparer un second athlÃ¨te sur le mÃªme graphique.

## âœ¨ FonctionnalitÃ©s principales

- **ğŸ” Recherche Intelligente** : AutocomplÃ©tion pour trouver les athlÃ¨tes (bases FFA et World Athletics).
- **ğŸš€ Scraping Haute Performance** : Moteur de scraping **asynchrone** (`httpx` + `asyncio`) capable de rÃ©cupÃ©rer des carriÃ¨res entiÃ¨res en quelques secondes.
- **ğŸŒ Multi-Sources** :
  - Source primaire : **FFA** (bases.athle.fr)
  - Fallback : **World Athletics** (si l'athlÃ¨te n'est pas trouvÃ© en France).
- **ğŸ“Š Visualisation Interactive (Plotly)** :
  - Vue principale **mono-athlÃ¨te** (parcours simple par dÃ©faut)
  - **Comparaison optionnelle** avec un 2e athlÃ¨te
  - Choix du type de graphique : **Nuage de points** ou **Lignes + points**
  - ContrÃ´les d'analyse : **Axe X (Date / Ã‚ge / AnnÃ©e)** et **Filtre performance (Toutes / Best annÃ©e / Best Ã¢ge)**
  - Infobulle enrichie : performance, date, lieu, Ã¢ge, type indoor/outdoor, source (FFA/WA)
- **ğŸ’¾ Base de DonnÃ©es Robuste** : Stockage persistant sur **PostgreSQL** (via NeonDB ou local) pour Ã©viter de re-scraper les donnÃ©es existantes.
- **âš¡ Mise Ã  jour intelligente** : DÃ©tection des doublons et mise Ã  jour incrÃ©mentale.

## ğŸ› ï¸ Stack Technique

- **Langage** : Python 3.9+
- **Interface** : [Streamlit](https://streamlit.io/)
- **Base de donnÃ©es** : PostgreSQL, SQLAlchemy, Psycopg2
- **Scraping** :
  - `httpx` (Asynchrone HTTP/2)
  - `BeautifulSoup4` & `Selectolax` (Parsing HTML)
- **Data Science** : Pandas, NumPy
- **Visualisation** : Plotly (app), Matplotlib/Seaborn (notebooks d'exploration)

## ğŸ“‚ Structure du projet

```
Scrapping-ffa/
â”œâ”€â”€ app.py                 # ğŸš€ Point d'entrÃ©e de l'application Streamlit
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ .env                   # Variables d'environnement (non versionnÃ©)
â”œâ”€â”€ exploration/           # Notebooks d'exploration (athle_live, graph_plotly, etc.)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ ffa_fast.py    # Scraper asynchrone optimisÃ© pour la FFA
â”‚   â”‚   â”œâ”€â”€ wa_utils.py    # Gestion de l'API et du scraping World Athletics
â”‚   â”‚   â”œâ”€â”€ athlete_utils.py # Gestion BDD et nettoyage des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ http_utils.py  # Utilitaires requÃªtes HTTP
â”‚   â”‚   â””â”€â”€ file_utils.py  # Conversion de temps et formats
â”‚   â””â”€â”€ data_storage/      # Gestionnaires de base de donnÃ©es
```

## ğŸš€ Installation et Utilisation

### 1. Cloner le projet
```bash
git clone https://github.com/votre-username/Scrapping-ffa.git
cd Scrapping-ffa
```

### 2. Installer les dÃ©pendances
Il est recommandÃ© d'utiliser un environnement virtuel.
```bash
pip install -r requirements.txt
```

### 3. Configuration (.env)
CrÃ©ez un fichier `.env` Ã  la racine du projet et ajoutez vos identifiants :
```properties
# Connexion PostgreSQL (ex: NeonDB, Supabase, ou Local)
DB_URL=postgresql://user:password@host:port/dbname?sslmode=require

# Configuration World Athletics (Optionnel)
WA_API_URL=https://api.worldathletics.org/v1
WA_API_KEY=votre_cle_api
```

### 4. Lancer l'application
```bash
streamlit run app.py
```
L'application sera accessible sur `http://localhost:8501`.

## ğŸ”„ Mise Ã  jour incrÃ©mentale de la base

Le script [update_athletes.py](update_athletes.py) met Ã  jour les performances en mode idempotent:
- il re-scrape les rÃ©sultats des athlÃ¨tes Ã  rafraÃ®chir,
- il n'insÃ¨re que les nouvelles lignes (dÃ©duplication SQL via contrainte unique),
- il met Ã  jour `last_update` uniquement si la rÃ©cupÃ©ration est techniquement rÃ©ussie.

### Lancement manuel
```bash
python update_athletes.py --batch 10
```

### Lancement en boucle (pÃ©riode de compÃ©tition)
```bash
python update_athletes.py --loop --delay 600 --batch 10
```

ParamÃ¨tres:
- `--batch`: nombre d'athlÃ¨tes traitÃ©s par batch
- `--delay`: pause entre deux batches en secondes (en mode `--loop`)

### Lancement Windows prÃªt scheduler
Le script [update_loop.bat](update_loop.bat) :
- active l'environnement virtuel,
- crÃ©e automatiquement le dossier `logs` si nÃ©cessaire,
- Ã©crit les traces dans [logs/update.log](logs/update.log).

Tu peux le brancher dans le Planificateur de tÃ¢ches Windows pour une exÃ©cution quotidienne.
Important: le PC doit Ãªtre allumÃ© (ou rÃ©veillable) au moment prÃ©vu.

### ExÃ©cution depuis tÃ©lÃ©phone
Possible de maniÃ¨re indirecte (bureau Ã  distance vers ton PC), puis lecture du log dans [logs/update.log](logs/update.log).

### Presets Task Scheduler (Windows)

Commande utilisÃ©e dans les presets:

```powershell
cmd /c "C:\Users\Lucas\Documents\DATA_SCIENCE\Scrapping-ffa\update_loop.bat"
```

Preset `Normal` (1 fois / jour Ã  06:00):

```powershell
schtasks /Create /TN "ScrappingFFA-Update-Normal" /TR "cmd /c \"C:\Users\Lucas\Documents\DATA_SCIENCE\Scrapping-ffa\update_loop.bat\"" /SC DAILY /ST 06:00 /F
```

Preset `Intense` (2 fois / jour: 07:00 et 19:00):

```powershell
schtasks /Create /TN "ScrappingFFA-Update-Intense-AM" /TR "cmd /c \"C:\Users\Lucas\Documents\DATA_SCIENCE\Scrapping-ffa\update_loop.bat\"" /SC DAILY /ST 07:00 /F
schtasks /Create /TN "ScrappingFFA-Update-Intense-PM" /TR "cmd /c \"C:\Users\Lucas\Documents\DATA_SCIENCE\Scrapping-ffa\update_loop.bat\"" /SC DAILY /ST 19:00 /F
```

Commandes utiles:

```powershell
# Lister les tÃ¢ches
schtasks /Query /TN "ScrappingFFA-Update-*"

# Lancer une tÃ¢che immÃ©diatement
schtasks /Run /TN "ScrappingFFA-Update-Normal"

# Supprimer un preset
schtasks /Delete /TN "ScrappingFFA-Update-Normal" /F
schtasks /Delete /TN "ScrappingFFA-Update-Intense-AM" /F
schtasks /Delete /TN "ScrappingFFA-Update-Intense-PM" /F
```

Notes:
- Le PC doit Ãªtre allumÃ© (ou rÃ©veillable) au moment d'exÃ©cution.
- Les traces restent dans [logs/update.log](logs/update.log).

## ğŸ§ª Notebooks
Les notebooks Jupyter d'exploration sont regroupÃ©s dans le dossier `exploration/` pour les tests de scraping, analyses et prototypage de visualisation.

## ğŸ§­ ExpÃ©rience utilisateur (rÃ©sumÃ©)
- **Sidebar structurÃ©e** : `AthlÃ¨te` â†’ `Comparaison` â†’ `Analyse` â†’ `AvancÃ©`
- **Comparaison progressive** : l'utilisateur commence avec 1 athlÃ¨te puis ajoute le 2e uniquement si besoin
- **Affichage avancÃ©** : rÃ©glage de hauteur du graphique dans un panneau repliable

## ğŸ‘¤ Auteur
Projet dÃ©veloppÃ© par **AurÃ©lien Vaudois**.
Contributions bienvenues !
